@online{chiaruttini2024,
  title = {{{ABBA}}, a Novel Tool for Whole-Brain Mapping, Reveals Brain-Wide Differences in Immediate Early Genes Induction Following Learning},
  author = {Chiaruttini, Nicolas and Castoldi, Carlo and Requie, Linda Maria and Camarena-Delgado, Carmen and Dal Bianco, Beatrice and Gräff, Johannes and Seitz, Arne and Silva, Bianca A.},
  date = {2024-09-06},
  doi = {10.1101/2024.09.06.611625},
  url = {http://biorxiv.org/lookup/doi/10.1101/2024.09.06.611625},
  urldate = {2024-09-12},
  abstract = {Abstract           Unbiased characterization of whole-brain cytoarchitecture represents an invaluable tool for understanding brain function. For this, precise mapping of histological markers from 2D sections onto 3D brain atlases is pivotal. Here, we present two novel software tools facilitating this process: Aligning Big Brains and Atlases (ABBA), designed to streamline the precise and efficient registration of 2D sections to 3D reference atlases, and BraiAn, an integrated suite for multi-marker automated segmentation, whole-brain statistical analysis, and data visualisation. Combining these tools, we performed a comprehensive comparative study of the whole-brain expression of three of the most widely used immediate early genes (IEGs). Thanks to their neural activity-dependent expression, IEGs have been used for decades as a proxy of neural activity to generate unbiased mapping of activity following behaviour, but their respective induction in response to neuronal activation across the entire brain remains unclear. To address this question, we systematically compared the brain-wide expression cFos, Arc and NPAS4, three abundantly used IEGs, across three different behavioural conditions related to memory. Our results highlight major differences in both their distribution and induction patterns, indicating that they do not represent equivalent markers across brain areas or activity states, but can provide instead complementary information.},
  langid = {english},
  pubstate = {prepublished}
}

@article{bankhead2017,
  title = {{{QuPath}}: {{Open}} Source Software for Digital Pathology Image Analysis},
  shorttitle = {{{QuPath}}},
  author = {Bankhead, Peter and Loughrey, Maurice B. and Fernández, José A. and Dombrowski, Yvonne and McArt, Darragh G. and Dunne, Philip D. and McQuaid, Stephen and Gray, Ronan T. and Murray, Liam J. and Coleman, Helen G. and James, Jacqueline A. and Salto-Tellez, Manuel and Hamilton, Peter W.},
  date = {2017-12-04},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {7},
  number = {1},
  pages = {16878},
  issn = {2045-2322},
  doi = {10.1038/s41598-017-17204-5},
  url = {https://www.nature.com/articles/s41598-017-17204-5},
  urldate = {2023-09-06},
  abstract = {Abstract             QuPath is new bioimage analysis software designed to meet the growing need for a user-friendly, extensible, open-source solution for digital pathology and whole slide image analysis. In addition to offering a comprehensive panel of tumor identification and high-throughput biomarker evaluation tools, QuPath provides researchers with powerful batch-processing and scripting functionality, and an extensible platform with which to develop and share new algorithms to analyze complex tissue images. Furthermore, QuPath’s flexible design makes it suitable for a wide range of additional image analysis applications across biomedical research.},
  langid = {english}
}
@article{yates2019,
  title = {{{QUINT}}: {{Workflow}} for {{Quantification}} and {{Spatial Analysis}} of {{Features}} in {{Histological Images From Rodent Brain}}},
  shorttitle = {{{QUINT}}},
  author = {Yates, Sharon C. and Groeneboom, Nicolaas E. and Coello, Christopher and Lichtenthaler, Stefan F. and Kuhn, Peer-Hendrik and Demuth, Hans-Ulrich and Hartlage-Rübsamen, Maike and Roßner, Steffen and Leergaard, Trygve and Kreshuk, Anna and Puchades, Maja A. and Bjaalie, Jan G.},
  date = {2019-12-03},
  journaltitle = {Frontiers in Neuroinformatics},
  shortjournal = {Front. Neuroinform.},
  volume = {13},
  pages = {75},
  issn = {1662-5196},
  doi = {10.3389/fninf.2019.00075},
  url = {https://www.frontiersin.org/article/10.3389/fninf.2019.00075/full},
  urldate = {2024-11-19},
  langid = {english}
}
@article{puchades2019,
  title = {Spatial Registration of Serial Microscopic Brain Images to Three-Dimensional Reference Atlases with the {{QuickNII}} Tool},
  author = {Puchades, Maja A. and Csucs, Gergely and Ledergerber, Debora and Leergaard, Trygve B. and Bjaalie, Jan G.},
  editor = {Malmierca, Manuel S.},
  date = {2019-05-29},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {14},
  number = {5},
  pages = {e0216796},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0216796},
  abstract = {Modern high throughput brain wide profiling techniques for cells and their morphology, connectivity, and other properties, make the use of reference atlases with 3D coordinate frameworks essential. However, anatomical location of observations made in microscopic sectional images from rodent brains is typically determined by comparison with 2D anatomical reference atlases. A major challenge in this regard is that microscopic sections often are cut with orientations deviating from the standard planes used in the reference atlases, resulting in inaccuracies and a need for tedious correction steps. Overall, efficient tools for registration of large series of section images to reference atlases are currently not widely available. Here we present QuickNII, a stand-alone software tool for semi-automated affine spatial registration of sectional image data to a 3D reference atlas coordinate framework. A key feature in the tool is the capability to generate user defined cut planes through the reference atlas, matching the orientation of the cut plane of the sectional image data. The reference atlas is transformed to match anatomical landmarks in the corresponding experimental images. In this way, the spatial relationship between experimental image and atlas is defined, without introducing distortions in the original experimental images. Following anchoring of a limited number of sections containing key landmarks, transformations are propagated across the entire series of sectional images to reduce the amount of manual steps required. By having coordinates assigned to the experimental images, further analysis of the distribution of features extracted from the images is greatly facilitated.},
  langid = {english}
}
@article{carey2023,
  title = {{{DeepSlice}}: Rapid Fully Automatic Registration of Mouse Brain Imaging to a Volumetric Atlas},
  shorttitle = {{{DeepSlice}}},
  author = {Carey, Harry and Pegios, Michael and Martin, Lewis and Saleeba, Chris and Turner, Anita J. and Everett, Nicholas A. and Bjerke, Ingvild E. and Puchades, Maja A. and Bjaalie, Jan G. and McMullan, Simon},
  date = {2023-09-21},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {5884},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-41645-4},
  abstract = {Abstract             Registration of data to a common frame of reference is an essential step in the analysis and integration of diverse neuroscientific data. To this end, volumetric brain atlases enable histological datasets to be spatially registered and analyzed, yet accurate registration remains expertise-dependent and slow. In order to address this limitation, we have trained a neural network, DeepSlice, to register mouse brain histological images to the Allen Brain Common Coordinate Framework, retaining registration accuracy while improving speed by {$>$}1000 fold.},
  langid = {english}
}
@article{berg2019,
  title = {Ilastik: Interactive Machine Learning for (Bio)Image Analysis},
  shorttitle = {Ilastik},
  author = {Berg, Stuart and Kutra, Dominik and Kroeger, Thorben and Straehle, Christoph N. and Kausler, Bernhard X. and Haubold, Carsten and Schiegg, Martin and Ales, Janez and Beier, Thorsten and Rudy, Markus and Eren, Kemal and Cervantes, Jaime I and Xu, Buote and Beuttenmueller, Fynn and Wolny, Adrian and Zhang, Chong and Koethe, Ullrich and Hamprecht, Fred A. and Kreshuk, Anna},
  date = {2019-12},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {16},
  number = {12},
  pages = {1226--1232},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/s41592-019-0582-9},
  langid = {english}
}
@article{tyson2021,
  title = {A Deep Learning Algorithm for {{3D}} Cell Detection in Whole Mouse Brain Image Datasets},
  author = {Tyson, Adam L. and Rousseau, Charly V. and Niedworok, Christian J. and Keshavarzi, Sepiedeh and Tsitoura, Chryssanthi and Cossell, Lee and Strom, Molly and Margrie, Troy W.},
  editor = {Berry, Hugues},
  date = {2021-05-28},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {17},
  number = {5},
  pages = {e1009074},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1009074},
  abstract = {Understanding the function of the nervous system necessitates mapping the spatial distributions of its constituent cells defined by function, anatomy or gene expression. Recently, developments in tissue preparation and microscopy allow cellular populations to be imaged throughout the entire rodent brain. However, mapping these neurons manually is prone to bias and is often impractically time consuming. Here we present an open-source algorithm for fully automated 3D detection of neuronal somata in mouse whole-brain microscopy images using standard desktop computer hardware. We demonstrate the applicability and power of our approach by mapping the brain-wide locations of large populations of cells labeled with cytoplasmic fluorescent proteins expressed via retrograde trans-synaptic viral infection.},
  langid = {english}
}
@article{tyson2022,
  title = {Accurate Determination of Marker Location within Whole-Brain Microscopy Images},
  author = {Tyson, Adam L. and Vélez-Fort, Mateo and Rousseau, Charly V. and Cossell, Lee and Tsitoura, Chryssanthi and Lenzi, Stephen C. and Obenhaus, Horst A. and Claudi, Federico and Branco, Tiago and Margrie, Troy W.},
  date = {2022-01-18},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {12},
  number = {1},
  pages = {867},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-04676-9},
  abstract = {Abstract             High-resolution whole-brain microscopy provides a means for post hoc determination of the location of implanted devices and labelled cell populations that are necessary to interpret in vivo experiments designed to understand brain function. Here we have developed two plugins (brainreg and brainreg-segment) for the Python-based image viewer napari, to accurately map any object in a common coordinate space. We analysed the position of dye-labelled electrode tracks and two-photon imaged cell populations expressing fluorescent proteins. The precise location of probes and cells were physiologically interrogated and revealed accurate segmentation with near-cellular resolution.},
  langid = {english}
}
@article{schindelin2012,
  title = {Fiji: An Open-Source Platform for Biological-Image Analysis},
  shorttitle = {Fiji},
  author = {Schindelin, Johannes and Arganda-Carreras, Ignacio and Frise, Erwin and Kaynig, Verena and Longair, Mark and Pietzsch, Tobias and Preibisch, Stephan and Rueden, Curtis and Saalfeld, Stephan and Schmid, Benjamin and Tinevez, Jean-Yves and White, Daniel James and Hartenstein, Volker and Eliceiri, Kevin and Tomancak, Pavel and Cardona, Albert},
  date = {2012-07},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {9},
  number = {7},
  pages = {676--682},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.2019},
  langid = {english}
}
@inproceedings{bogovic2016,
  title = {Robust Registration of Calcium Images by Learned Contrast Synthesis},
  booktitle = {2016 {{IEEE}} 13th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  author = {Bogovic, John A. and Hanslovsky, Philipp and Wong, Allan and Saalfeld, Stephan},
  date = {2016-04},
  pages = {1123--1126},
  publisher = {IEEE},
  location = {Prague, Czech Republic},
  doi = {10.1109/ISBI.2016.7493463},
  abstract = {Multi-modal image registration is a challenging task that is vital to fuse complementary signals for subsequent analyses. Despite much research into cost functions addressing this challenge, there exist cases in which these are ineffective. In this work, we show that (1) this is true for the registration of in-vivo Drosophila brain volumes visualizing genetically encoded calcium indicators to an nc82 atlas and (2) that machine learning based contrast synthesis can yield improvements. More specifically, the number of subjects for which the registration outright failed was greatly reduced (from 40\% to 15\%) by using a synthesized image.},
  eventtitle = {2016 {{IEEE}} 13th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}} 2016)},
  isbn = {978-1-4799-2349-6},
  langid = {english}
}
@software{reback2020pandas,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}
@InProceedings{ mckinney-proc-scipy-2010,
  author    = { {W}es {M}c{K}inney },
  title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
  booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
  pages     = { 56 - 61 },
  year      = { 2010 },
  editor    = { {S}t\'efan van der {W}alt and {J}arrod {M}illman },
  doi       = { 10.25080/Majora-92bf1922-00a }
}
@article{wang2020,
  title = {The {{Allen Mouse Brain Common Coordinate Framework}}: {{A 3D Reference Atlas}}},
  shorttitle = {The {{Allen Mouse Brain Common Coordinate Framework}}},
  author = {Wang, Quanxin and Ding, Song-Lin and Li, Yang and Royall, Josh and Feng, David and Lesnar, Phil and Graddis, Nile and Naeemi, Maitham and Facer, Benjamin and Ho, Anh and Dolbeare, Tim and Blanchard, Brandon and Dee, Nick and Wakeman, Wayne and Hirokawa, Karla E. and Szafer, Aaron and Sunkin, Susan M. and Oh, Seung Wook and Bernard, Amy and Phillips, John W. and Hawrylycz, Michael and Koch, Christof and Zeng, Hongkui and Harris, Julie A. and Ng, Lydia},
  date = {2020-05},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {181},
  number = {4},
  pages = {936-953.e20},
  issn = {00928674},
  doi = {10.1016/j.cell.2020.04.007},
  abstract = {Recent large-scale collaborations are generating major surveys of cell types and connections in the mouse brain, collecting large amounts of data across modalities, spatial scales, and brain areas. Successful integration of these data requires a standard 3D reference atlas. Here, we present the Allen Mouse Brain Common Coordinate Framework (CCFv3) as such a resource. We constructed an average template brain at 10 mm voxel resolution by interpolating high resolution in-plane serial two-photon tomography images with 100 mm z-sampling from 1,675 young adult C57BL/6J mice. Then, using multimodal reference data, we parcellated the entire brain directly in 3D, labeling every voxel with a brain structure spanning 43 isocortical areas and their layers, 329 subcortical gray matter structures, 81 fiber tracts, and 8 ventricular structures. CCFv3 can be used to analyze, visualize, and integrate multimodal and multiscale datasets in 3D and is openly accessible (https://atlas.brain-map.org/).},
  langid = {english}
}
@article{kleven2023,
  title = {Waxholm {{Space}} Atlas of the Rat Brain: A {{3D}} Atlas Supporting Data Analysis and Integration},
  author = {Kleven, Heidi and Bjerke, Ingvild E. and Clascá, Francisco and Groenewegen, Henk J. and Bjaalie, Jan G. and Leergaard, Trygve B.},
  date = {2023-11-01},
  journaltitle = {Nature Methods},
  shortjournal = {Nature Methods},
  volume = {20},
  number = {11},
  pages = {1822--1829},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-02034-3},
  abstract = {Volumetric brain atlases are increasingly used to integrate and analyze diverse experimental neuroscience data acquired from animal models, but until recently a publicly available digital atlas with complete coverage of the rat brain has been missing. Here we present an update of the Waxholm Space rat brain atlas, a comprehensive open-access volumetric atlas resource. This brain atlas features annotations of 222 structures, of which 112 are new and 57 revised compared to previous versions. It provides a detailed map of the cerebral cortex, hippocampal region, striatopallidal areas, midbrain dopaminergic system, thalamic cell groups, the auditory system and main fiber tracts. We document the criteria underlying the annotations and demonstrate how the atlas with related tools and workflows can be used to support interpretation, integration, analysis and dissemination of experimental rat brain data.}
}
@article{kunst2019,
  title = {A {{Cellular-Resolution Atlas}} of the {{Larval Zebrafish Brain}}},
  author = {Kunst, Michael and Laurell, Eva and Mokayes, Nouwar and Kramer, Anna and Kubo, Fumi and Fernandes, António M. and Förster, Dominique and Dal Maschio, Marco and Baier, Herwig},
  date = {2019-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {103},
  number = {1},
  pages = {21-38.e5},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.04.034},
  abstract = {Understanding brain-wide neuronal dynamics requires a detailed map of the underlying circuit architecture. We built an interactive cellular-resolution atlas of the zebrafish brain at 6 days post-fertilization (dpf) based on the reconstructions of over 2,000 individually GFP-labeled neurons. We clustered our dataset in ‘‘morphotypes,’’ establishing a unique database of quantitatively described neuronal morphologies together with their spatial coordinates in vivo. Over 100 transgene expression patterns were imaged separately and co-registered with the single-neuron atlas. By annotating 72 non-overlapping brain regions, we generated from our dataset an inter-areal wiring diagram of the larval brain, which serves as ground truth for synapse-scale, electron microscopic reconstructions. Interrogating our atlas by ‘‘virtual tract tracing’’ has already revealed previously unknown wiring principles in the tectum and the cerebellum. In conclusion, we present here an evolving computational resource and visualization tool, which will be essential to map function to structure in a vertebrate brain.},
  langid = {english}
}
@article{lazcano2021,
  title = {{{MRI-}} and Histologically Derived Neuroanatomical Atlas of the {{Ambystoma}} Mexicanum (Axolotl)},
  author = {Lazcano, Ivan and Cisneros-Mejorado, Abraham and Concha, Luis and Ortiz-Retana, Juan José and Garza-Villarreal, Eduardo A. and Orozco, Aurea},
  date = {2021-05-10},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {9850},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-89357-3},
  abstract = {Amphibians are an important vertebrate model system to understand anatomy, genetics and physiology. Importantly, the brain and spinal cord of adult urodels (salamanders) have an incredible regeneration capacity, contrary to anurans (frogs) and the rest of adult vertebrates. Among these amphibians, the axolotl (Ambystoma mexicanum) has gained most attention because of the surge in the understanding of central nervous system (CNS) regeneration and the recent sequencing of its whole genome. However, a complete comprehension of the brain anatomy is not available. In the present study we created a magnetic resonance imaging (MRI) atlas of the in vivo neuroanatomy of the juvenile axolotl brain. This is the first MRI atlas for this species and includes three levels: (1) 82 regions of interest (ROIs) and a version with 64 ROIs; (2) a division of the brain according to the embryological origin of the neural tube, and (3) left and right hemispheres. Additionally, we localized the myelin rich regions of the juvenile brain. The atlas, the template that the atlas was derived from, and a masking file, can be found on Zenodo at https://doi.org/10.5281/zenodo.4595016. This MRI brain atlas aims to be an important tool for future research of the axolotl brain and that of other amphibians.}
}
